==========================================================================================================================================================================
-- JSON FILE
==========================================================================================================================================================================

-- IMPORTANT: BEFORE CREATING ANY TABLE, MAKE SURE YOU RUN THIS COMMAND 
ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-hcatalog-core-1.1.0-cdh5.11.2.jar;


-- CREATE EXTERNAL TABLE
 
CREATE EXTERNAL TABLE IF NOT EXISTS amazon_reviews_table(reviewerid string, asin string,
reviewername string, helpful array<int>, reviewtext string, overall double, summary string,
unixreviewtime bigint) ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
with serdeproperties  ('paths' = '')
location '/common_folder/amazon_reviews';

-- RUN QUERY ON THIS TABLE 

select reviewerid, reviewername, asin, unixreviewtime from amazon_reviews_table limit 10;

==========================================================================================================================================================================
-- CSV FILE
==========================================================================================================================================================================

DROP TABLE bollywood_movies_table;

CREATE EXTERNAL TABLE IF NOT EXISTS Bollywood_Movies_table(
  Movie STRING,
  Lead STRING,
  Rdate STRING,
  Ocollection DOUBLE,
  Wcollection DOUBLE,
  Fwcollection DOUBLE,
  Tcollection DOUBLE,
  Verdict STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
  lines terminated by '\n' 
LOCATION '/common_folder/bollywood/'
tblproperties ("skip.header.line.count"="1");



-- CREATE EXTERNAL TABLE 
CREATE EXTERNAL TABLE IF NOT EXISTS Airline_Table(
 SlNo       INT,
 Year       INT,
 Month	    INT,
 DayofMonth INT,
 DayOfWeek	INT,
 DepTime	INT,
 CRSDepTime	INT,
 ArrTime	INT,
 CRSArrTime	INT,
 UniqueCarrier	STRING,
 FlightNum	INT,
 TailNum    STRING,
 ActualElapsedTime	INT,
 CRSElapsedTime		INT,
 AirTime	    INT,
 ArrDelay	    INT,
 DepDelay	    INT,
 Origin         STRING,
 Dest           STRING,
 Distance       INT,	
 TaxiIn         INT,
 TaxiOut        INT,
 Cancelled      INT,
 CancellationCode   STRING,
 Diverted	    INT,
 CarrierDelay	INT,
 WeatherDelay   INT,
 NASDelay       INT,
 SecurityDelay  INT,
 LateAircraftDelay  INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
  lines terminated by '\n' 
LOCATION '/common_folder/airlines/'
tblproperties ("skip.header.line.count"="1");

==========================================================================================================================================================================
-- PARTITION THE DATA
==========================================================================================================================================================================

-- IMPORTANT: BEFORE PARTITIONING ANY TABLE, MAKE SURE YOU RUN THESE COMMANDS 
SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;


-- First drop the table 
drop table amazon_reviews_year_month_partitioned;

-- Then create external table 
create external table if not exists amazon_reviews_year_month_partitioned
(reviewerid string, asin string, reviewername string, helpful array<int>, reviewtext string,
overall double, summary string, unixreviewtime bigint) partitioned by (yr int, mnth int)
location '/user/hive/warehouse/give_your_partition_folder_name';


-- Then insert the data in the table 
insert overwrite table amazon_reviews_year_month_partitioned partition(yr, mnth)
select reviewerid, asin, reviewername, helpful, reviewtext,
overall, summary, unixreviewtime, year(from_unixtime(unixreviewtime)) as yr, month(from_unixtime(unixreviewtime)) as mnth
from amazon_reviews_table;

==========================================================================================================================================================================
-- DML Query
==========================================================================================================================================================================


-- FIND NUMBER OF REVIEWERS 
select count(*) as review_count, count(distinct reviewerid) as reviewer_count,
count(distinct asin) as product_count, min(unixreviewtime) as min_time,
max(unixreviewtime) as max_time
from amazon_reviews_table;

-- 	review_count	reviewer_count	product_count	min_time		max_time
--	630466			177428			22950			959904000		1406073600
 

-- AVERAGE NUMBER OF REVIEWS FOR EACH REVIEWER 
select avg(review_count)
from (
	select reviewerid, count(*) as review_count
	from amazon_reviews_table
	group by reviewerid
	)a ;

-- 3.55
	
-- REVIEWS SORTED BY DATE 
select year(from_unixtime(unixreviewtime)) as yr, count(*) as review_count
from amazon_reviews_table
group by year(from_unixtime(unixreviewtime));

-- 2007	21569
-- 2008	36965
-- 2000	4
-- 2009	39810
-- 2001	1
-- 2010	57119
-- 2002	4
-- 2011	97492
-- 2003	3
-- 2012	112809
-- 2004	7
-- 2013	178744
-- 2005	185
-- 2014	80689
-- 2006	5065


==========================================================================================================================================================================
-- ORC Table Query
==========================================================================================================================================================================

-- PARTITION THE DATA  
-- IMPORTANT: BEFORE PARTITIONING ANY TABLE, MAKE SURE YOU RUN THESE COMMANDS 
SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;


-- First drop the table 
drop table amazon_reviews_year_month_partitioned;

-- Then create external table 
create external table if not exists amazon_reviews_year_month_partitioned
(reviewerid string, asin string, reviewername string, helpful array<int>, reviewtext string,
overall double, summary string, unixreviewtime bigint) partitioned by (yr int, mnth int)
location '/user/hive/warehouse/rkl.isharm_gmail_amazon';


-- Then insert the data in the table 
insert overwrite table amazon_reviews_year_month_partitioned partition(yr, mnth)
select reviewerid, asin, reviewername, helpful, reviewtext,
overall, summary, unixreviewtime, year(from_unixtime(unixreviewtime)) as yr, month(from_unixtime(unixreviewtime)) as mnth
from amazon_reviews_table;

SELECT * FROM airlines_partitioned limit 10

-- First, create ORC table 
create external table if not exists amazon_reviews_year_month_partition_orc
(reviewerid string, asin string, reviewername string, helpful array<int>, reviewtext string,
overall double, summary string, unixreviewtime bigint) partitioned by (yr int, mnth int)
stored as orc location '/user/hive/warehouse/rkl.isharm_gmail_amazon_orc'
tblproperties ("orc.compress"="SNAPPY");

-- Then, write data from partition table into ORC table 

insert overwrite table amazon_reviews_year_month_partition_orc partition(yr , mnth)
select * from amazon_reviews_year_month_partitioned;

-- Now you can query the ORC table 
-- First, let's find the length of some sample reviews 

select reviewtext, size(split(reviewtext, ' ')) as n_words
from amazon_reviews_year_month_partition_orc
where yr = 2013 and mnth = 1
limit 10;

-- Now, let's find the average length of the reviews and the variance in the length 

select avg( size(split(reviewtext, ' ')) ) as avg_length, variance( size(split(reviewtext, ' ')) ) as varinc
from amazon_reviews_year_month_partition_orc
where yr = 2013 and mnth = 1;

-- Then, let's find the average number of words for every rating level 
select avg(size(split(reviewtext, ' '))) as words, overall as rating
from amazon_reviews_year_month_partition_orc
where yr = 2013 and mnth = 1
group by overall;


-- Let's do some more analysis on the ORC tables 

-- Let's find which product topped the popularity charts for the most number of months 
-- We have considered months beyond 2005. You can change this year and test the code. 
-- The execution time will increase as it queries more and more years 
select asin, count(*) as charting_mnths
from(
    select yr, mnth, asin, popularity, rnk
    from(

        select yr, mnth, asin, popularity, rank() over (partition by yr, mnth order by popularity desc) as rnk
        from(
            select yr, mnth, asin, count(*) as popularity
            from amazon_reviews_year_month_partition_orc
            where yr >= 2005
            group by yr, mnth, asin
        )a

    )b
    where rnk < 10
)c
group by asin
order by charting_mnths desc;



-- Now, let's do some basic text analytics 

-- First, view the individual tokens in lowercase 
select reviewtext, sentences(lower(reviewtext))
from amazon_reviews_year_month_partition_orc
where yr = 2013 and mnth = 1
limit 10;

-- Then, view the most popular ngrams present in all these reviews 
select explode( ngrams( sentences( lower(reviewtext) ), 2, 6))
FROM amazon_reviews_year_month_partition_orc
where yr = 2013 and mnth = 1;


==========================================================================================================================================================================
-- ORC Table Query
==========================================================================================================================================================================



-- IMPORTANT: BEFORE CREATING ANY TABLE, MAKE SURE YOU RUN THIS COMMAND 
ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-hcatalog-core-1.1.0-cdh5.11.2.jar;

-- PARTITION THE DATA  
-- IMPORTANT: BEFORE PARTITIONING ANY TABLE, MAKE SURE YOU RUN THESE COMMANDS 
SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;


-- First drop the table 
drop table airline_table_year_month_partitioned;

-- Then create external table 
create external table if not exists airline_table_year_month_partitioned
(SlNo       INT, DayofMonth INT, DayOfWeek	INT, DepTime	INT, CRSDepTime	INT, ArrTime	INT, CRSArrTime	INT, UniqueCarrier	STRING, FlightNum	INT, TailNum    STRING,
 ActualElapsedTime	INT, CRSElapsedTime		INT, AirTime	    INT, ArrDelay	    INT, DepDelay	    INT, Origin         STRING, Dest           STRING, Distance       INT, TaxiIn         INT,
 TaxiOut        INT, Cancelled      INT, CancellationCode   STRING, Diverted	    INT, CarrierDelay	INT, WeatherDelay   INT, NASDelay       INT, SecurityDelay  INT, LateAircraftDelay  INT) partitioned by (Year INT, Month INT)
location '/user/hive/warehouse/rkl.isharm_gmail_airlines';


-- Then insert the data in the table 
insert overwrite table airline_table_year_month_partitioned partition(Year, Month)
SELECT airline_table.slno,airline_table.year,airline_table.month,airline_table.dayofmonth,airline_table.dayofweek,airline_table.deptime,airline_table.crsdeptime,airline_table.arrtime,
airline_table.crsarrtime,airline_table.uniquecarrier,airline_table.flightnum,airline_table.tailnum,airline_table.actualelapsedtime,	airline_table.crselapsedtime,	airline_table.airtime,
airline_table.arrdelay,	airline_table.depdelay,	airline_table.origin,	airline_table.dest,	airline_table.distance,	airline_table.taxiin,	airline_table.taxiout,	airline_table.cancelled,
airline_table.cancellationcode,	airline_table.diverted	,airline_table.carrierdelay,	airline_table.weatherdelay,	airline_table.nasdelay,	airline_table.securitydelay,
airline_table.lateaircraftdelay FROM airline_table

SELECT * FROM airline_table_year_month_partitioned limit 10

-- First, create ORC table 
create external table if not exists airline_table_year_month_partitioned_orc
(
SlNo       INT, DayofMonth INT, DayOfWeek	INT, DepTime	INT, CRSDepTime	INT, ArrTime	INT, CRSArrTime	INT, UniqueCarrier	STRING, FlightNum	INT, TailNum    STRING,
 ActualElapsedTime	INT, CRSElapsedTime		INT, AirTime	    INT, ArrDelay	    INT, DepDelay	    INT, Origin         STRING, Dest           STRING, Distance       INT, TaxiIn         INT,
 TaxiOut        INT, Cancelled      INT, CancellationCode   STRING, Diverted	    INT, CarrierDelay	INT, WeatherDelay   INT, NASDelay       INT, SecurityDelay  INT, LateAircraftDelay  INT
) partitioned by (Year int, Month int)
stored as orc location '/user/hive/warehouse/rkl.isharm_gmail_airlines_orc'
tblproperties ("orc.compress"="SNAPPY");

-- Then, write data from partition table into ORC table 

insert overwrite table airline_table_year_month_partitioned_orc partition(Year ,Month)
select * from airline_table_year_month_partitioned 


=====================================================================================
-- NGrams
======================================================================================

 

--IMPORTANT: BEFORE CREATING ANY TABLE, MAKE SURE YOU RUN THIS COMMAND 
ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-hcatalog-core-1.1.0-cdh5.11.2.jar;

SELECT explode( ngrams( sentences( lower(reviewtext) ), 2, 6))
FROM amazon_reviews_year_month_partition_orc
where yr = 2013 and mnth = 1;

=====================================================================================
-- SQOOP
======================================================================================
-- entering the mysql environment
mysql -h sqoopdb.upg.cloudlab.com -u your_username -p your_password

-- select a database 
use database_name;

-- drop table if exists
drop table iris;

-- creating a table in the database
create table iris(sepal_length varchar(20), sepal_width varchar(20), petal_length varchar(20), petal_width varchar(20), class varchar(20));

-- select the data from the created table
select * from iris;

-- exiting from mysql
exit

sqoop export --connect jdbc:mysql://sqoopdb.upg.cloudlab.com/rkl_isharm_gmail -username rkl_isharm_gmail --password rkl.isharm_gmailrohzy --table iris --export-dir iris_data/*

-- checking if the export has happened
mysql -h sqoopdb.upg.cloudlab.com -u rkl_isharm_gmail -p rkl.isharm_gmailrohzy

-- select the database
use database_name;

-- running a select query
select * from iris where sepal_length > 6.0;


-- creating a table in the database
create table iris(sepal_length varchar(20), sepal_width varchar(20), petal_length varchar(20), petal_width varchar(20), class varchar(20));
CREATE TABLE Bollywood_Movies_table(
  Movie varchar(50),
  Lead varchar(50),
  Rdate varchar(20),
  Ocollection DOUBLE,
  Wcollection DOUBLE,
  Fwcollection DOUBLE,
  Tcollection DOUBLE,
  Verdict varchar(20));

sqoop export --connect jdbc:mysql://sqoopdb.upg.cloudlab.com/rkl_isharm_gmail -username rkl_isharm_gmail --password rkl.isharm_gmailrohzy --table Bollywood_Movies_table --export-dir /common_folder/bollywood/*

sqoop job --create lstdb -- list-databases --connect jdbc:mysql://sqoopdb.upg.cloudlab.com/rkl_isharm_gmail -username rkl_isharm_gmail -P

sqoop job --list


SELECT percentile(size(split(reviewtext, ' ')),0.75)
FROM amazon_reviews_year_month_partition_orc
where yr = 2008 and mnth = 10